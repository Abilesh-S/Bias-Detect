# Bias-Detect
A tool to detect and rephrase biased text using LLMs

# PROBLEM STATEMENT
Develop a tool that analyses text generated by an LLM for potential biases (e.g., gender, cultural) and suggests revisions to make it more neutral. This could improve fairness in AI-generated content for applications like hiring or news.
# Key Requirements
 - Use an LLM to analyze input text for biased phrases (e.g., with sentiment analysis or keyword detection).
- Generate suggestions for neutral rephrasing using the same or another LLM.
- Build a simple interface (e.g., Streamlit) for users to input text and view results.





